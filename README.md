# üìú **Application de Recherche Augment√©e - Constitution du Burkina Faso**  

Une application bas√©e sur l'intelligence artificielle utilisant LangChain et Ollama pour effectuer une recherche augment√©e dans la Constitution du Burkina Faso. Elle comprend un backend API d√©velopp√© avec FastAPI et une interface utilisateur construite avec Streamlit.

---

## **üöÄ D√©ploiement Local**

### **1. Pr√©requis**  
- **Python 3.9+**  
- **Docker (facultatif)**  

### **2. Installation**
1. Clonez le d√©p√¥t :
   ```bash
   git clone https://github.com/votre-compte/burkina_law_rag.git
   cd burkina_law_rag
   ```

2. Cr√©ez et activez l'environnement virtuel :
   ```bash
   python -m venv rag_env
   source rag_env/bin/activate
   ```

3. Installez les d√©pendances :
   ```bash
   pip install -r requirements.txt
   ```

4. Configurez les variables d'environnement :
   ```bash
   cp .env.example .env
   ```

---

### **3. Installation de Ollama et LLaMA3.2**  

#### **3.1. Installation d‚ÄôOllama**
1. **T√©l√©chargez Ollama** :  
   Suivez les instructions d‚Äôinstallation officielles sur le site d‚ÄôOllama :  
   [Installation d'Ollama](https://ollama.com/download)

2. **Lancez Ollama Localement** :
   ```bash
   ollama serve --host localhost --port 11434
   ```

---

#### **3.2. Installation de LLaMA 3.2**
1. **T√©l√©chargement du Mod√®le LLaMA 3.2**
   ```bash
   ollama pull llama3.2
   ```

2. **V√©rification du Mod√®le** :
   ```bash
   ollama list
   ```

3. **Ajoutez LLaMA √† vos Variables d‚ÄôEnvironnement** :
   ```env
   MODEL=llama3.2
   OLLAMA_HOST=http://localhost:11434
   ```

---

### **4. Lancement de l'API Backend (FastAPI)**
```bash
fastapi dev backend/main.py
```

---

### **5. Lancement de l'Interface Utilisateur (Streamlit)**
```bash
streamlit run frontend/app.py
```

---

### **6. Acc√®s √† l'Application**
- **Backend API** : [http://localhost:8000/docs](http://localhost:8000/docs) (Swagger)  
- **Frontend Streamlit** : [http://localhost:8501](http://localhost:8501)

---

## **üîß Utilisation avec Docker**
Si vous pr√©f√©rez Docker, utilisez `docker-compose` :  

```bash
docker-compose up --build
```

---

## **üìä Fonctionnalit√©s**
1. **Recherche Augment√©e :** Interrogez la Constitution avec des requ√™tes en langage naturel.  
2. **Mod√®le IA Local :** Utilise LLaMA en local via Ollama.  
3. **Backend API REST :** D√©velopp√© avec FastAPI, documentation incluse.  
4. **Interface Utilisateur Simple :** Streamlit pour une exp√©rience utilisateur fluide.  

---

## **üì¶ Technologies Utilis√©es**
- **Langues :** Python 3.9+  
- **Frameworks Backend :** FastAPI, FAISS  
- **Frontend :** Streamlit  
- **IA & Mod√®les :** LangChain, Ollama, LLaMA  

---

## **üîí S√©curit√© et Confidentialit√©**
- Les cl√©s API et configurations sont stock√©es dans `.env`.  
- **Important :** Ne partagez pas ce fichier `.env` en public.

---

## **üìÑ Licence**
Ce projet est sous licence **MIT**.

---
