# ðŸ“œ **Application de Recherche AugmentÃ©e - Constitution du Burkina Faso**  

Une application basÃ©e sur l'intelligence artificielle utilisant LangChain et Ollama pour effectuer une recherche augmentÃ©e dans la Constitution du Burkina Faso. Elle comprend un backend API dÃ©veloppÃ© avec FastAPI et une interface utilisateur construite avec Streamlit.

---

## **ðŸš€ DÃ©ploiement Local**

### **1. PrÃ©requis**  
- **Python 3.12+**  
- **Docker (facultatif)**

### **2. Installation**
1. Clonez le dÃ©pÃ´t :
   ```bash
   git clone https://github.com/votre-compte/burkina_law_rag.git
   cd burkina_law_rag
   ```

2. CrÃ©ez et activez l'environnement virtuel :
   ```bash
   python -m venv rag_env
   source rag_env/bin/activate
   ```

3. Installez les dÃ©pendances :
   ```bash
   pip install -r requirements.txt
   ```

4. Configurez les variables d'environnement :
   ```bash
   cp .env.example .env
   ```

---

### **3. Installation de Ollama et LLaMA3.2**  

#### **3.1. Installation dâ€™Ollama**
1. **TÃ©lÃ©chargez Ollama** :  
   Suivez les instructions dâ€™installation officielles sur le site dâ€™Ollama :  
   [Installation d'Ollama](https://ollama.com/download)

2. **Lancez Ollama Localement** :
   ```bash
   ollama serve --host localhost --port 11434
   ```

---

#### **3.2. Installation de LLaMA 3.2**
1. **TÃ©lÃ©chargement du ModÃ¨le LLaMA 3.2**
   ```bash
   ollama pull llama3.2
   ```

2. **VÃ©rification du ModÃ¨le** :
   ```bash
   ollama list
   ```

3. **Ajoutez LLaMA Ã  vos Variables dâ€™Environnement** :
   ```env
   MODEL=llama3.2
   BASE_URL=http://localhost:11434
   ```

---

### **4. Lancement de l'API Backend (FastAPI)**
```bash
fastapi dev backend/main.py
```

---

### **5. Lancement de l'Interface Utilisateur (Streamlit)**
```bash
streamlit run frontend/app.py
```

---

### **6. AccÃ¨s Ã  l'Application**
- **Backend API** : [http://localhost:8000/docs](http://localhost:8000/docs) (Swagger)  
- **Frontend Streamlit** : [http://localhost:8501](http://localhost:8501)

---

## **ðŸ”§ Utilisation avec Docker**
Si vous prÃ©fÃ©rez Docker, utilisez `docker-compose` :  

```bash
docker-compose up --build
```

---

## **ðŸ“Š FonctionnalitÃ©s**
1. **Recherche AugmentÃ©e :** Interrogez la Constitution avec des requÃªtes en langage naturel.  
2. **ModÃ¨le IA Local :** Utilise LLaMA en local via Ollama.  
3. **Backend API REST :** DÃ©veloppÃ© avec FastAPI.  
4. **Interface Utilisateur Simple :** Streamlit pour une expÃ©rience utilisateur fluide.  

---

## **ðŸ“¦ Technologies UtilisÃ©es**
- **Langues :** Python 3.12+  
- **Frameworks Backend :** FastAPI, FAISS  
- **Frontend :** Streamlit  
- **IA & ModÃ¨les :** LangChain, Ollama, LLaMA  

---

## **ðŸ“„ Licence**
Ce projet est sous licence **MIT**.

---
